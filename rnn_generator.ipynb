{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/straattaal.txt']\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "files = findFiles('data/*.txt')\n",
    "print(files)\n",
    "import re\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    lines = [s.lower() for s in lines]\n",
    "    lines = [re.sub(\"[\\t\\s]\", '', s) for s in lines]\n",
    "    return lines\n",
    "\n",
    "for filename in files:\n",
    "    lines = readLines(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('vtdlcg bnuhrzmjskpefiçxoway', 27, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters = set(\" \".join(lines))\n",
    "all_letters = \"\"\n",
    "for s in letters:\n",
    "\tall_letters += all_letters.join(s)\n",
    "\n",
    "n_letters = len(all_letters) + 1 # EOS\n",
    "all_letters, len(all_letters), n_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li in range(len(line)):\n",
    "        letter = line[li]\n",
    "        tensor[li][0][all_letters.find(letter)] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def targetTensor(line):\n",
    "    letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))]\n",
    "    letter_indexes.append(n_letters - 1) # EOS\n",
    "    return torch.LongTensor(letter_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomChoice(l):\n",
    "\treturn l[torch.randint(len(l), size=[1])]\n",
    "def randomTrain():\n",
    "\tline = randomChoice(lines)\n",
    "\tinput_line_tensor = inputTensor(line)\n",
    "\ttarget_line_tensor = targetTensor(line)\n",
    "\treturn input_line_tensor, target_line_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 1, 28]), torch.Size([5]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, target = randomTrain()\n",
    "inputs.size(), target.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.tanh(self.i2h(combined))\n",
    "        output = self.i2o(hidden)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "learning_rate = 0.0001\n",
    "\n",
    "def train(input_line_tensor, target_line_tensor):\n",
    "    target_line_tensor.unsqueeze_(-1)\n",
    "    hidden = rnn.initHidden()\n",
    "    rnn.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for i in range(input_line_tensor.size(0)):\n",
    "        output, hidden = rnn(input_line_tensor[i], hidden)\n",
    "        l = criterion(output, target_line_tensor[i])\n",
    "        loss += l\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output, loss.item() / input_line_tensor.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(n_letters, 128, n_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 8s (5000 10%) 2.6905\n",
      "0m 17s (10000 20%) 2.4666\n",
      "0m 27s (15000 30%) 2.6794\n",
      "0m 36s (20000 40%) 2.2552\n",
      "0m 46s (25000 50%) 2.2539\n",
      "0m 55s (30000 60%) 2.0132\n",
      "1m 5s (35000 70%) 2.5100\n",
      "1m 14s (40000 80%) 2.3528\n",
      "1m 23s (45000 90%) 2.4330\n",
      "1m 32s (50000 100%) 2.6964\n"
     ]
    }
   ],
   "source": [
    "n_iters = 50000\n",
    "print_every = 5000\n",
    "plot_every = 500\n",
    "all_losses = []\n",
    "total_loss = 0 # Reset every plot_every iters\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    output, loss = train(*randomTrain())\n",
    "    total_loss += loss\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss))\n",
    "\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(total_loss / plot_every)\n",
    "        total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(start_letter='a', maxn=20, temp=0):\n",
    "\twith torch.no_grad():\n",
    "\t\tinput = inputTensor(start_letter)\n",
    "\t\thidden = rnn.initHidden()\n",
    "\t\toutput_name = start_letter\n",
    "\t\tfor i in range(maxn):\n",
    "\t\t\toutput, hidden = rnn(input[0], hidden)\n",
    "\t\t\tif temp != 1:\n",
    "\t\t\t\t# print(\"use temp\")\n",
    "\t\t\t\tprobs = torch.softmax(output, 1) / temp\n",
    "\t\t\t\tdist = torch.distributions.Categorical(probs)\n",
    "\t\t\t\tpick = dist.sample()\n",
    "\t\t\telse:\n",
    "\t\t\t\ttopv, topi = output.topk(1)\n",
    "\t\t\t\tpick = topi[0][0]\n",
    "\t\t\tif pick == n_letters - 1:\n",
    "\t\t\t\tbreak\n",
    "\t\t\telse:\n",
    "\t\t\t\tletter = all_letters[pick]\n",
    "\t\t\t\toutput_name += letter\n",
    "\t\t\tinput = inputTensor(letter)\n",
    "\t\treturn output_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " aaa\n",
      "eaaaa\n",
      "kaaaa\n",
      "baaa\n",
      "taa\n",
      "iaaa\n",
      "çaaa\n",
      "laie\n",
      "laaa\n",
      "saa\n",
      "laaa\n",
      "saaa\n",
      "foee\n",
      "caaa\n",
      "haaa\n",
      "uaa\n",
      "caaa\n",
      "gaa\n",
      "kanae\n",
      "çaaa\n",
      "paa\n",
      "naaa\n",
      "zaaa\n",
      "faaa\n",
      "paa\n",
      "iaaa\n",
      "ioee\n",
      "faaa\n",
      "daaa\n",
      "caaaa\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "\tprint(sample(start_letter=randomChoice(all_letters), temp=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'ç']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(\"vtdlcg bnuhrzmjskpefiçxoway\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
